{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde8a3f7",
   "metadata": {},
   "source": [
    "<h1><center>EN.553.688: Computing for Applied Mathematics - Final Assignment</center></h1>\n",
    "<h1><center>Dayou Ren</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caafe94a",
   "metadata": {},
   "source": [
    "# Steps and ideas\n",
    "\n",
    "Read in train data frame.\n",
    "\n",
    "## Data frame sanity check\n",
    "\n",
    "Check the dimensions of the data frame.\n",
    "\n",
    "Check for the existence of NaNs in the data frame.\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "Add edited_2023 column.\n",
    "\n",
    "Imputation: subsitute NaNs in each column with the median in that column.\n",
    "\n",
    "Scale the data.\n",
    "\n",
    "## Split data frame\n",
    "\n",
    "Split the data frame into 1:4. 20% testing and 80% training.\n",
    "\n",
    "## Regression and Classification Models:\n",
    "\n",
    "### For length prediction\n",
    "Linear Regression\n",
    "\n",
    "Decision Tree Regression\n",
    "\n",
    "### For word_present prediction:\n",
    "\n",
    "Decision Tree (with threshold adjustment)\n",
    "\n",
    "Logistic Regression (with threshold adjustment)\n",
    "\n",
    "Support Vector Machine with Linear Kernel and class weights adjustment\n",
    "\n",
    "K-th Nearest Neighbor\n",
    "\n",
    "Random Forest with threshold adjustment\n",
    "\n",
    "### For edited_2023 prediction:\n",
    "\n",
    "Decision Tree (with threshold adjustment)\n",
    "\n",
    "Logistic Regression (with threshold adjustment)\n",
    "\n",
    "Support Vector Machine with Linear Kernel and class weights adjustment\n",
    "\n",
    "K-th Nearest Neighbot\n",
    "\n",
    "Random Forest with threshold adjustment\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "Decision Tree Regression is a better option for length predictions compared to Linear Regression.\n",
    "\n",
    "It seems like Random Forest is the best option for word_present and edited_2023 predictions with the constraint of lowering FPR.\n",
    "\n",
    "## Apply trained models to test dataset\n",
    "Read in test data frame. Same preprocessing necessary as above.\n",
    "\n",
    "Apply models.\n",
    "\n",
    "Export to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34fe889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix, mean_absolute_error, precision_recall_curve, roc_curve\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58f174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (200000, 44)\n",
      "URLID              0\n",
      "educat          4031\n",
      "polit           3977\n",
      "people          4000\n",
      "anger           4083\n",
      "human           4022\n",
      "excess          3944\n",
      "city            4044\n",
      "ocean           4044\n",
      "math            3917\n",
      "social          3948\n",
      "rest            4042\n",
      "gram            4031\n",
      "analysis        4102\n",
      "data            3961\n",
      "process         4001\n",
      "problem         4003\n",
      "example         4087\n",
      "sales           4020\n",
      "product         4051\n",
      "question        3917\n",
      "qualit          3879\n",
      "categor         4161\n",
      "first           3905\n",
      "transaction     4029\n",
      "survey          4037\n",
      "optim           3921\n",
      "number          4018\n",
      "conduct         4000\n",
      "experienc       3904\n",
      "visual          4062\n",
      "audio           4082\n",
      "elect           3959\n",
      "decision        3991\n",
      "petrol          4089\n",
      "mouse           4108\n",
      "danger          3963\n",
      "heart           3885\n",
      "soul            4032\n",
      "grade           4079\n",
      "elderly         3975\n",
      "length             0\n",
      "date               0\n",
      "word_present       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLID</th>\n",
       "      <th>educat</th>\n",
       "      <th>polit</th>\n",
       "      <th>people</th>\n",
       "      <th>anger</th>\n",
       "      <th>human</th>\n",
       "      <th>excess</th>\n",
       "      <th>city</th>\n",
       "      <th>ocean</th>\n",
       "      <th>math</th>\n",
       "      <th>...</th>\n",
       "      <th>petrol</th>\n",
       "      <th>mouse</th>\n",
       "      <th>danger</th>\n",
       "      <th>heart</th>\n",
       "      <th>soul</th>\n",
       "      <th>grade</th>\n",
       "      <th>elderly</th>\n",
       "      <th>length</th>\n",
       "      <th>date</th>\n",
       "      <th>word_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243838</th>\n",
       "      <td>URLID_HLGM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15118</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180391</th>\n",
       "      <td>URLID_TIQI</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142859</td>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107367</th>\n",
       "      <td>URLID_EVZN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46591</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>URLID_SBDC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40552</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48203</th>\n",
       "      <td>URLID_NHNM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35071</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URLID  educat  polit  people  anger  human  excess  city  ocean  \\\n",
       "243838  URLID_HLGM     0.0    0.0     2.0    0.0    0.0     0.0   1.0    0.0   \n",
       "180391  URLID_TIQI     2.0    0.0     0.0    2.0   22.0     3.0  16.0    0.0   \n",
       "107367  URLID_EVZN     0.0    3.0     0.0    1.0    0.0     0.0   1.0    0.0   \n",
       "19660   URLID_SBDC     0.0    0.0     NaN    0.0    0.0     0.0   0.0    0.0   \n",
       "48203   URLID_NHNM     NaN    0.0     0.0    0.0    0.0     0.0   0.0    0.0   \n",
       "\n",
       "        math  ...  petrol  mouse  danger  heart  soul  grade  elderly  length  \\\n",
       "243838   1.0  ...     0.0    0.0     0.0    0.0   0.0    0.0      0.0   15118   \n",
       "180391   2.0  ...     0.0    0.0     0.0    2.0   0.0    1.0      0.0  142859   \n",
       "107367   0.0  ...     0.0    0.0     1.0    1.0   0.0    0.0      0.0   46591   \n",
       "19660    0.0  ...     0.0    0.0     0.0    0.0   0.0    3.0      0.0   40552   \n",
       "48203    0.0  ...     0.0    0.0     0.0    1.0   0.0    0.0      0.0   35071   \n",
       "\n",
       "              date  word_present  \n",
       "243838  2023-03-07             0  \n",
       "180391  2023-03-26             1  \n",
       "107367  2023-01-01             1  \n",
       "19660   2023-02-02             1  \n",
       "48203   2023-02-03             0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_pickle('./training_data.pkl')\n",
    "# dataset sanity check\n",
    "print(f'Shape: {df_train.shape}')\n",
    "nan_counts = df_train.isna().sum()\n",
    "print(nan_counts)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71499870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLID           0\n",
      "educat          0\n",
      "polit           0\n",
      "people          0\n",
      "anger           0\n",
      "human           0\n",
      "excess          0\n",
      "city            0\n",
      "ocean           0\n",
      "math            0\n",
      "social          0\n",
      "rest            0\n",
      "gram            0\n",
      "analysis        0\n",
      "data            0\n",
      "process         0\n",
      "problem         0\n",
      "example         0\n",
      "sales           0\n",
      "product         0\n",
      "question        0\n",
      "qualit          0\n",
      "categor         0\n",
      "first           0\n",
      "transaction     0\n",
      "survey          0\n",
      "optim           0\n",
      "number          0\n",
      "conduct         0\n",
      "experienc       0\n",
      "visual          0\n",
      "audio           0\n",
      "elect           0\n",
      "decision        0\n",
      "petrol          0\n",
      "mouse           0\n",
      "danger          0\n",
      "heart           0\n",
      "soul            0\n",
      "grade           0\n",
      "elderly         0\n",
      "length          0\n",
      "date            0\n",
      "word_present    0\n",
      "dtype: int64\n",
      "word_present\n",
      "1    127531\n",
      "0     72469\n",
      "Name: count, dtype: int64\n",
      "edited_2023\n",
      "1    137628\n",
      "0     62372\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLID</th>\n",
       "      <th>educat</th>\n",
       "      <th>polit</th>\n",
       "      <th>people</th>\n",
       "      <th>anger</th>\n",
       "      <th>human</th>\n",
       "      <th>excess</th>\n",
       "      <th>city</th>\n",
       "      <th>ocean</th>\n",
       "      <th>math</th>\n",
       "      <th>...</th>\n",
       "      <th>mouse</th>\n",
       "      <th>danger</th>\n",
       "      <th>heart</th>\n",
       "      <th>soul</th>\n",
       "      <th>grade</th>\n",
       "      <th>elderly</th>\n",
       "      <th>length</th>\n",
       "      <th>date</th>\n",
       "      <th>word_present</th>\n",
       "      <th>edited_2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243838</th>\n",
       "      <td>URLID_HLGM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15118</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180391</th>\n",
       "      <td>URLID_TIQI</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142859</td>\n",
       "      <td>2023-03-26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107367</th>\n",
       "      <td>URLID_EVZN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46591</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>URLID_SBDC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40552</td>\n",
       "      <td>2023-02-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48203</th>\n",
       "      <td>URLID_NHNM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35071</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URLID  educat  polit  people  anger  human  excess  city  ocean  \\\n",
       "243838  URLID_HLGM     0.0    0.0     2.0    0.0    0.0     0.0   1.0    0.0   \n",
       "180391  URLID_TIQI     2.0    0.0     0.0    2.0   22.0     3.0  16.0    0.0   \n",
       "107367  URLID_EVZN     0.0    3.0     0.0    1.0    0.0     0.0   1.0    0.0   \n",
       "19660   URLID_SBDC     0.0    0.0     0.0    0.0    0.0     0.0   0.0    0.0   \n",
       "48203   URLID_NHNM     0.0    0.0     0.0    0.0    0.0     0.0   0.0    0.0   \n",
       "\n",
       "        math  ...  mouse  danger  heart  soul  grade  elderly  length  \\\n",
       "243838   1.0  ...    0.0     0.0    0.0   0.0    0.0      0.0   15118   \n",
       "180391   2.0  ...    0.0     0.0    2.0   0.0    1.0      0.0  142859   \n",
       "107367   0.0  ...    0.0     1.0    1.0   0.0    0.0      0.0   46591   \n",
       "19660    0.0  ...    0.0     0.0    0.0   0.0    3.0      0.0   40552   \n",
       "48203    0.0  ...    0.0     0.0    1.0   0.0    0.0      0.0   35071   \n",
       "\n",
       "             date  word_present  edited_2023  \n",
       "243838 2023-03-07             0            1  \n",
       "180391 2023-03-26             1            1  \n",
       "107367 2023-01-01             1            1  \n",
       "19660  2023-02-02             1            1  \n",
       "48203  2023-02-03             0            1  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imputation\n",
    "selected_columns = df_train.columns[1:-3]\n",
    "medians = df_train[selected_columns].median()\n",
    "df_train[selected_columns] = df_train[selected_columns].fillna(medians)\n",
    "filled_nan_counts = df_train.isna().sum()\n",
    "print(filled_nan_counts)\n",
    "\n",
    "# add edited_2023\n",
    "df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "df_train['edited_2023'] = (df_train['date'].dt.year == 2023).astype(int)\n",
    "\n",
    "# check training sample distributions\n",
    "print(df_train['word_present'].value_counts())\n",
    "print(df_train['edited_2023'].value_counts())\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298e2302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['URLID', 'educat', 'polit', 'people', 'anger', 'human', 'excess', 'city', 'ocean', 'math', 'social', 'rest', 'gram', 'analysis', 'data', 'process', 'problem', 'example', 'sales', 'product', 'question', 'qualit', 'categor', 'first', 'transaction', 'survey', 'optim', 'number', 'conduct', 'experienc', 'visual', 'audio', 'elect', 'decision', 'petrol', 'mouse', 'danger', 'heart', 'soul', 'grade', 'elderly', 'length', 'date', 'word_present', 'edited_2023']\n",
      "(160000, 40)\n",
      "(40000, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>date</th>\n",
       "      <th>word_present</th>\n",
       "      <th>edited_2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144062</th>\n",
       "      <td>19331</td>\n",
       "      <td>2021-01-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172958</th>\n",
       "      <td>47949</td>\n",
       "      <td>2023-03-23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144499</th>\n",
       "      <td>24984</td>\n",
       "      <td>2023-02-19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125899</th>\n",
       "      <td>36188</td>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70240</th>\n",
       "      <td>23018</td>\n",
       "      <td>2023-03-11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        length       date  word_present  edited_2023\n",
       "144062   19331 2021-01-09             1            0\n",
       "172958   47949 2023-03-23             1            1\n",
       "144499   24984 2023-02-19             1            1\n",
       "125899   36188 2023-01-12             0            1\n",
       "70240    23018 2023-03-11             0            1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the dataframe\n",
    "feature = df_train.iloc[:, 1:-4]\n",
    "scaler = StandardScaler()\n",
    "feature = scaler.fit_transform(feature)\n",
    "response = df_train.iloc[:, -4:]\n",
    "\n",
    "print(df_train.columns.tolist())\n",
    "\n",
    "f_train, f_test, r_train, r_test = train_test_split(feature, response, test_size=0.2)\n",
    "print(f_train.shape)\n",
    "print(f_test.shape)\n",
    "\n",
    "r_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7a9cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate 'length' response variable\n",
    "length_r_train = r_train['length']\n",
    "length_r_test = r_test['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f9c4a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 8754.398345611608\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression for length prediction\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(f_train, length_r_train)\n",
    "\n",
    "r_pred = model_lr.predict(f_test)\n",
    "mae = mean_absolute_error(length_r_test, r_pred)\n",
    "\n",
    "print(f'MAE: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc2c789a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 7598.373634157763\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regression for length prediction\n",
    "model_dtr = DecisionTreeRegressor()\n",
    "model_dtr.fit(f_train, length_r_train)\n",
    "\n",
    "r_pred = model_dtr.predict(f_test)\n",
    "mae = mean_absolute_error(length_r_test, r_pred)\n",
    "\n",
    "print(f'MAE: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "412472e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate 'word_present' response variable\n",
    "wp_r_train = r_train['word_present']\n",
    "wp_r_test = r_test['word_present']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26509e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0.239875 0.12045 ]\n",
      " [0.156325 0.48335 ]]\n",
      "True Positive Rate: 0.755618087309962\n",
      "False Positive Rate: 0.33428155137722887\n",
      "\n",
      "Adjusted Confusion Matrix:\n",
      "[[0.360325 0.      ]\n",
      " [0.639675 0.      ]]\n",
      "True Positive Rate: 0.0\n",
      "False Positive Rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dtc_wp = DecisionTreeClassifier()\n",
    "dtc_wp.fit(f_train, wp_r_train)\n",
    "\n",
    "r_pred = dtc_wp.predict(f_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(wp_r_test, r_pred)/f_test.shape[0]\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "print(f'True Positive Rate: {conf_matrix[1][1]/(conf_matrix[1][1]+conf_matrix[1][0])}')\n",
    "\n",
    "print(f'False Positive Rate: {conf_matrix[0][1]/(conf_matrix[0][0]+conf_matrix[0][1])}')\n",
    "\n",
    "print()\n",
    "\n",
    "# adjust threshold\n",
    "probabilities = dtc_wp.predict_proba(f_test)[:, 1]\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(wp_r_test, probabilities)\n",
    "\n",
    "selected_threshold = threshold[np.argmin(np.abs(fpr - 0.05))]\n",
    "\n",
    "r_pred_adjusted = (probabilities >= selected_threshold).astype(int)\n",
    "\n",
    "conf_matrix_adjusted = confusion_matrix(wp_r_test, r_pred_adjusted)/f_test.shape[0]\n",
    "\n",
    "print(f'Adjusted Confusion Matrix:\\n{conf_matrix_adjusted}')\n",
    "print(f'True Positive Rate: {conf_matrix_adjusted[1][1]/(conf_matrix_adjusted[1][1]+conf_matrix_adjusted[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix_adjusted[0][1]/(conf_matrix_adjusted[0][0]+conf_matrix_adjusted[0][1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6300e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0.289825 0.0705  ]\n",
      " [0.267325 0.37235 ]]\n",
      "True Positive Rate: 0.5820924688318287\n",
      "False Positive Rate: 0.19565669881357106\n",
      "\n",
      "Adjusted Confusion Matrix:\n",
      "[[0.3423   0.018025]\n",
      " [0.44365  0.196025]]\n",
      "True Positive Rate: 0.3064446789385235\n",
      "False Positive Rate: 0.05002428363283147\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "model_logr_wp = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model_logr_wp.fit(f_train, wp_r_train)\n",
    "\n",
    "r_pred = model_logr_wp.predict(f_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(wp_r_test, r_pred)/f_test.shape[0]\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "print(f'True Positive Rate: {conf_matrix[1][1]/(conf_matrix[1][1]+conf_matrix[1][0])}')\n",
    "\n",
    "print(f'False Positive Rate: {conf_matrix[0][1]/(conf_matrix[0][0]+conf_matrix[0][1])}')\n",
    "\n",
    "print()\n",
    "\n",
    "# adjust threshold\n",
    "probabilities = model_logr_wp.predict_proba(f_test)[:, 1]\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(wp_r_test, probabilities)\n",
    "\n",
    "selected_threshold = threshold[np.argmin(np.abs(fpr - 0.05))]\n",
    "\n",
    "r_pred_adjusted = (probabilities >= selected_threshold).astype(int)\n",
    "\n",
    "conf_matrix_adjusted = confusion_matrix(wp_r_test, r_pred_adjusted)/f_test.shape[0]\n",
    "\n",
    "print(f'Adjusted Confusion Matrix:\\n{conf_matrix_adjusted}')\n",
    "print(f'True Positive Rate: {conf_matrix_adjusted[1][1]/(conf_matrix_adjusted[1][1]+conf_matrix_adjusted[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix_adjusted[0][1]/(conf_matrix_adjusted[0][0]+conf_matrix_adjusted[0][1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfe5b7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0.33905  0.021275]\n",
      " [0.433675 0.206   ]]\n",
      "True Positive Rate: 0.322038535193653\n",
      "False Positive Rate: 0.05904391868452091\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm_wp = LinearSVC(max_iter=100000, dual=False, class_weight={0:1, 1:0.32})\n",
    "svm_wp.fit(f_train, wp_r_train)\n",
    "\n",
    "r_pred = svm_wp.predict(f_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(wp_r_test, r_pred)/f_test.shape[0]\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'True Positive Rate: {conf_matrix[1][1]/(conf_matrix[1][1]+conf_matrix[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix[0][1]/(conf_matrix[0][0]+conf_matrix[0][1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02c70d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0.218975 0.14135 ]\n",
      " [0.140025 0.49965 ]]\n",
      "True Positive Rate: 0.781099777230625\n",
      "False Positive Rate: 0.39228474294040105\n",
      "Adjusted Confusion Matrix:\n",
      "[[0.341525 0.0188  ]\n",
      " [0.412675 0.227   ]]\n",
      "True Positive Rate: 0.3548677062570837\n",
      "False Positive Rate: 0.05217511968361896\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn_wp = KNeighborsClassifier(n_neighbors=99)\n",
    "knn_wp.fit(f_train, wp_r_train)\n",
    "\n",
    "r_pred = knn_wp.predict(f_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(wp_r_test, r_pred)/f_test.shape[0]\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'True Positive Rate: {conf_matrix[1][1]/(conf_matrix[1][1]+conf_matrix[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix[0][1]/(conf_matrix[0][0]+conf_matrix[0][1])}')\n",
    "\n",
    "# adjust threshold\n",
    "probabilities = knn_wp.predict_proba(f_test)[:, 1]\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(wp_r_test, probabilities)\n",
    "\n",
    "selected_threshold = threshold[np.argmin(np.abs(fpr - 0.05))]\n",
    "\n",
    "r_pred_adjusted = (probabilities >= selected_threshold).astype(int)\n",
    "\n",
    "conf_matrix_adjusted = confusion_matrix(wp_r_test, r_pred_adjusted)/f_test.shape[0]\n",
    "\n",
    "print(f'Adjusted Confusion Matrix:\\n{conf_matrix_adjusted}')\n",
    "print(f'True Positive Rate: {conf_matrix_adjusted[1][1]/(conf_matrix_adjusted[1][1]+conf_matrix_adjusted[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix_adjusted[0][1]/(conf_matrix_adjusted[0][0]+conf_matrix_adjusted[0][1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b01279ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0.2249   0.135425]\n",
      " [0.092175 0.5475  ]]\n",
      "True Positive Rate: 0.8559033884394419\n",
      "False Positive Rate: 0.37584125442309024\n",
      "Adjusted Confusion Matrix:\n",
      "[[0.34245  0.017875]\n",
      " [0.322675 0.317   ]]\n",
      "True Positive Rate: 0.49556415367178647\n",
      "False Positive Rate: 0.04960799278429196\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_wp = RandomForestClassifier(n_estimators=100, random_state=73)\n",
    "rf_wp.fit(f_train, wp_r_train)\n",
    "\n",
    "r_pred = rf_wp.predict(f_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(wp_r_test, r_pred)/f_test.shape[0]\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'True Positive Rate: {conf_matrix[1][1]/(conf_matrix[1][1]+conf_matrix[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix[0][1]/(conf_matrix[0][0]+conf_matrix[0][1])}')\n",
    "\n",
    "# adjust threshold\n",
    "probabilities = rf_wp.predict_proba(f_test)[:, 1]\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(wp_r_test, probabilities)\n",
    "\n",
    "selected_threshold_wp = threshold[np.argmin(np.abs(fpr - 0.05))]\n",
    "\n",
    "r_pred_adjusted = (probabilities >= selected_threshold_wp).astype(int)\n",
    "\n",
    "conf_matrix_adjusted = confusion_matrix(wp_r_test, r_pred_adjusted)/f_test.shape[0]\n",
    "\n",
    "print(f'Adjusted Confusion Matrix:\\n{conf_matrix_adjusted}')\n",
    "print(f'True Positive Rate: {conf_matrix_adjusted[1][1]/(conf_matrix_adjusted[1][1]+conf_matrix_adjusted[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix_adjusted[0][1]/(conf_matrix_adjusted[0][0]+conf_matrix_adjusted[0][1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b38be34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate 'edited_2023' response variable\n",
    "e2_r_train = r_train['edited_2023']\n",
    "e2_r_test = r_test['edited_2023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f1b0397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0.17755  0.128675]\n",
      " [0.183825 0.50995 ]]\n",
      "True Positive Rate: 0.7350365752585493\n",
      "False Positive Rate: 0.42019756714833867\n",
      "\n",
      "Adjusted Confusion Matrix:\n",
      "[[0.306225 0.      ]\n",
      " [0.693775 0.      ]]\n",
      "True Positive Rate: 0.0\n",
      "False Positive Rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dtc_e2 = DecisionTreeClassifier()\n",
    "dtc_e2.fit(f_train, e2_r_train)\n",
    "\n",
    "r_pred = dtc_e2.predict(f_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(e2_r_test, r_pred)/f_test.shape[0]\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "print(f'True Positive Rate: {conf_matrix[1][1]/(conf_matrix[1][1]+conf_matrix[1][0])}')\n",
    "\n",
    "print(f'False Positive Rate: {conf_matrix[0][1]/(conf_matrix[0][0]+conf_matrix[0][1])}')\n",
    "\n",
    "print()\n",
    "\n",
    "# adjust threshold\n",
    "probabilities = dtc_e2.predict_proba(f_test)[:, 1]\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(wp_r_test, probabilities)\n",
    "\n",
    "selected_threshold = threshold[np.argmin(np.abs(fpr - 0.05))]\n",
    "\n",
    "r_pred_adjusted = (probabilities >= selected_threshold).astype(int)\n",
    "\n",
    "conf_matrix_adjusted = confusion_matrix(e2_r_test, r_pred_adjusted)/f_test.shape[0]\n",
    "\n",
    "print(f'Adjusted Confusion Matrix:\\n{conf_matrix_adjusted}')\n",
    "print(f'True Positive Rate: {conf_matrix_adjusted[1][1]/(conf_matrix_adjusted[1][1]+conf_matrix_adjusted[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix_adjusted[0][1]/(conf_matrix_adjusted[0][0]+conf_matrix_adjusted[0][1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ee76706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0.24515  0.061075]\n",
      " [0.3223   0.371475]]\n",
      "True Positive Rate: 0.5354401643184029\n",
      "False Positive Rate: 0.1994448526410319\n",
      "\n",
      "Adjusted Confusion Matrix:\n",
      "[[0.29515  0.011075]\n",
      " [0.538025 0.15575 ]]\n",
      "True Positive Rate: 0.22449641454362004\n",
      "False Positive Rate: 0.03616621765042044\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "model_logr_e2 = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model_logr_e2.fit(f_train, e2_r_train)\n",
    "\n",
    "r_pred = model_logr_e2.predict(f_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(e2_r_test, r_pred)/f_test.shape[0]\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "print(f'True Positive Rate: {conf_matrix[1][1]/(conf_matrix[1][1]+conf_matrix[1][0])}')\n",
    "\n",
    "print(f'False Positive Rate: {conf_matrix[0][1]/(conf_matrix[0][0]+conf_matrix[0][1])}')\n",
    "\n",
    "print()\n",
    "\n",
    "# adjust threshold\n",
    "probabilities = model_logr_e2.predict_proba(f_test)[:, 1]\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(wp_r_test, probabilities)\n",
    "\n",
    "selected_threshold = threshold[np.argmin(np.abs(fpr - 0.05))]\n",
    "\n",
    "r_pred_adjusted = (probabilities >= selected_threshold).astype(int)\n",
    "\n",
    "conf_matrix_adjusted = confusion_matrix(e2_r_test, r_pred_adjusted)/f_test.shape[0]\n",
    "\n",
    "print(f'Adjusted Confusion Matrix:\\n{conf_matrix_adjusted}')\n",
    "print(f'True Positive Rate: {conf_matrix_adjusted[1][1]/(conf_matrix_adjusted[1][1]+conf_matrix_adjusted[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix_adjusted[0][1]/(conf_matrix_adjusted[0][0]+conf_matrix_adjusted[0][1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4878472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0.28925  0.016975]\n",
      " [0.501525 0.19225 ]]\n",
      "True Positive Rate: 0.27710713127454867\n",
      "False Positive Rate: 0.05543309657931259\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm_e2 = LinearSVC(max_iter=100000, dual=False, class_weight={0:1, 1:0.25})\n",
    "svm_e2.fit(f_train, e2_r_train)\n",
    "\n",
    "r_pred = svm_e2.predict(f_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(e2_r_test, r_pred)/f_test.shape[0]\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'True Positive Rate: {conf_matrix[1][1]/(conf_matrix[1][1]+conf_matrix[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix[0][1]/(conf_matrix[0][0]+conf_matrix[0][1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e819225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0.12495  0.181275]\n",
      " [0.1074   0.586375]]\n",
      "True Positive Rate: 0.8451947677561168\n",
      "False Positive Rate: 0.5919666911584619\n",
      "Adjusted Confusion Matrix:\n",
      "[[0.291625 0.0146  ]\n",
      " [0.516675 0.1771  ]]\n",
      "True Positive Rate: 0.25527008035746457\n",
      "False Positive Rate: 0.04767736141725855\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn_e2 = KNeighborsClassifier(n_neighbors=99)\n",
    "knn_e2.fit(f_train, e2_r_train)\n",
    "\n",
    "r_pred = knn_e2.predict(f_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(e2_r_test, r_pred)/f_test.shape[0]\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'True Positive Rate: {conf_matrix[1][1]/(conf_matrix[1][1]+conf_matrix[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix[0][1]/(conf_matrix[0][0]+conf_matrix[0][1])}')\n",
    "\n",
    "# adjust threshold\n",
    "probabilities = knn_e2.predict_proba(f_test)[:, 1]\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(e2_r_test, probabilities)\n",
    "\n",
    "selected_threshold = threshold[np.argmin(np.abs(fpr - 0.05))]\n",
    "\n",
    "r_pred_adjusted = (probabilities >= selected_threshold).astype(int)\n",
    "\n",
    "conf_matrix_adjusted = confusion_matrix(e2_r_test, r_pred_adjusted)/f_test.shape[0]\n",
    "\n",
    "print(f'Adjusted Confusion Matrix:\\n{conf_matrix_adjusted}')\n",
    "print(f'True Positive Rate: {conf_matrix_adjusted[1][1]/(conf_matrix_adjusted[1][1]+conf_matrix_adjusted[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix_adjusted[0][1]/(conf_matrix_adjusted[0][0]+conf_matrix_adjusted[0][1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9ef505a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[0.1477   0.158525]\n",
      " [0.093475 0.6003  ]]\n",
      "True Positive Rate: 0.865266116536341\n",
      "False Positive Rate: 0.5176749122377338\n",
      "Adjusted Confusion Matrix:\n",
      "[[0.290925 0.0153  ]\n",
      " [0.4317   0.262075]]\n",
      "True Positive Rate: 0.3777521530755648\n",
      "False Positive Rate: 0.04996326230712712\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_e2 = RandomForestClassifier(n_estimators=100, random_state=73)\n",
    "rf_e2.fit(f_train, e2_r_train)\n",
    "\n",
    "r_pred = rf_e2.predict(f_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(e2_r_test, r_pred)/f_test.shape[0]\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'True Positive Rate: {conf_matrix[1][1]/(conf_matrix[1][1]+conf_matrix[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix[0][1]/(conf_matrix[0][0]+conf_matrix[0][1])}')\n",
    "\n",
    "# adjust threshold\n",
    "probabilities = rf_e2.predict_proba(f_test)[:, 1]\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(e2_r_test, probabilities)\n",
    "\n",
    "selected_threshold_e2 = threshold[np.argmin(np.abs(fpr - 0.05))]\n",
    "\n",
    "r_pred_adjusted = (probabilities >= selected_threshold_e2).astype(int)\n",
    "\n",
    "conf_matrix_adjusted = confusion_matrix(e2_r_test, r_pred_adjusted)/f_test.shape[0]\n",
    "\n",
    "print(f'Adjusted Confusion Matrix:\\n{conf_matrix_adjusted}')\n",
    "print(f'True Positive Rate: {conf_matrix_adjusted[1][1]/(conf_matrix_adjusted[1][1]+conf_matrix_adjusted[1][0])}')\n",
    "print(f'False Positive Rate: {conf_matrix_adjusted[0][1]/(conf_matrix_adjusted[0][0]+conf_matrix_adjusted[0][1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e125671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (50000, 41)\n",
      "URLID             0\n",
      "educat         1018\n",
      "polit           941\n",
      "people          995\n",
      "anger          1050\n",
      "human           991\n",
      "excess          973\n",
      "city            988\n",
      "ocean           920\n",
      "math            968\n",
      "social          988\n",
      "rest            985\n",
      "gram            976\n",
      "analysis        985\n",
      "data           1025\n",
      "process         984\n",
      "problem        1037\n",
      "example        1002\n",
      "sales           999\n",
      "product        1015\n",
      "question       1010\n",
      "qualit          980\n",
      "categor         945\n",
      "first          1000\n",
      "transaction    1048\n",
      "survey          990\n",
      "optim          1017\n",
      "number          980\n",
      "conduct        1045\n",
      "experienc       987\n",
      "visual          995\n",
      "audio           947\n",
      "elect          1047\n",
      "decision        973\n",
      "petrol         1041\n",
      "mouse          1009\n",
      "danger         1044\n",
      "heart           960\n",
      "soul           1002\n",
      "grade           966\n",
      "elderly        1000\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLID</th>\n",
       "      <th>educat</th>\n",
       "      <th>polit</th>\n",
       "      <th>people</th>\n",
       "      <th>anger</th>\n",
       "      <th>human</th>\n",
       "      <th>excess</th>\n",
       "      <th>city</th>\n",
       "      <th>ocean</th>\n",
       "      <th>math</th>\n",
       "      <th>...</th>\n",
       "      <th>audio</th>\n",
       "      <th>elect</th>\n",
       "      <th>decision</th>\n",
       "      <th>petrol</th>\n",
       "      <th>mouse</th>\n",
       "      <th>danger</th>\n",
       "      <th>heart</th>\n",
       "      <th>soul</th>\n",
       "      <th>grade</th>\n",
       "      <th>elderly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61630</th>\n",
       "      <td>URLID_GNPF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32747</th>\n",
       "      <td>URLID_IIAA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231181</th>\n",
       "      <td>URLID_OOXK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152952</th>\n",
       "      <td>URLID_HCWK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22218</th>\n",
       "      <td>URLID_RXZL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URLID  educat  polit  people  anger  human  excess  city  ocean  \\\n",
       "61630   URLID_GNPF     1.0    1.0     NaN    0.0    0.0     0.0   1.0    0.0   \n",
       "32747   URLID_IIAA     0.0    0.0     1.0    0.0    0.0     0.0   3.0    0.0   \n",
       "231181  URLID_OOXK     0.0    2.0     6.0    0.0    0.0     0.0   0.0    0.0   \n",
       "152952  URLID_HCWK     0.0    0.0     5.0    2.0    0.0     0.0   0.0    0.0   \n",
       "22218   URLID_RXZL     0.0    0.0     0.0    0.0    1.0     0.0   1.0    0.0   \n",
       "\n",
       "        math  ...  audio  elect  decision  petrol  mouse  danger  heart  soul  \\\n",
       "61630    0.0  ...    0.0    4.0       0.0     0.0    0.0     0.0    0.0   0.0   \n",
       "32747    0.0  ...    0.0    1.0       0.0     0.0    0.0     0.0    0.0   0.0   \n",
       "231181   1.0  ...    0.0    2.0       0.0     1.0    0.0     0.0    0.0   0.0   \n",
       "152952   0.0  ...    0.0    0.0       0.0     0.0    0.0     2.0    0.0   0.0   \n",
       "22218    0.0  ...    0.0    2.0       0.0     0.0    0.0     0.0    0.0   0.0   \n",
       "\n",
       "        grade  elderly  \n",
       "61630     0.0      0.0  \n",
       "32747     1.0      0.0  \n",
       "231181    0.0      0.0  \n",
       "152952    0.0      0.0  \n",
       "22218     0.0      0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_pickle('./test_data.pkl')\n",
    "# dataset sanity check\n",
    "print(f'Shape: {df_test.shape}')\n",
    "nan_counts = df_test.isna().sum()\n",
    "print(nan_counts)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8eaee994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLID          0\n",
      "educat         0\n",
      "polit          0\n",
      "people         0\n",
      "anger          0\n",
      "human          0\n",
      "excess         0\n",
      "city           0\n",
      "ocean          0\n",
      "math           0\n",
      "social         0\n",
      "rest           0\n",
      "gram           0\n",
      "analysis       0\n",
      "data           0\n",
      "process        0\n",
      "problem        0\n",
      "example        0\n",
      "sales          0\n",
      "product        0\n",
      "question       0\n",
      "qualit         0\n",
      "categor        0\n",
      "first          0\n",
      "transaction    0\n",
      "survey         0\n",
      "optim          0\n",
      "number         0\n",
      "conduct        0\n",
      "experienc      0\n",
      "visual         0\n",
      "audio          0\n",
      "elect          0\n",
      "decision       0\n",
      "petrol         0\n",
      "mouse          0\n",
      "danger         0\n",
      "heart          0\n",
      "soul           0\n",
      "grade          0\n",
      "elderly        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLID</th>\n",
       "      <th>educat</th>\n",
       "      <th>polit</th>\n",
       "      <th>people</th>\n",
       "      <th>anger</th>\n",
       "      <th>human</th>\n",
       "      <th>excess</th>\n",
       "      <th>city</th>\n",
       "      <th>ocean</th>\n",
       "      <th>math</th>\n",
       "      <th>...</th>\n",
       "      <th>audio</th>\n",
       "      <th>elect</th>\n",
       "      <th>decision</th>\n",
       "      <th>petrol</th>\n",
       "      <th>mouse</th>\n",
       "      <th>danger</th>\n",
       "      <th>heart</th>\n",
       "      <th>soul</th>\n",
       "      <th>grade</th>\n",
       "      <th>elderly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61630</th>\n",
       "      <td>URLID_GNPF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32747</th>\n",
       "      <td>URLID_IIAA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231181</th>\n",
       "      <td>URLID_OOXK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152952</th>\n",
       "      <td>URLID_HCWK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22218</th>\n",
       "      <td>URLID_RXZL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URLID  educat  polit  people  anger  human  excess  city  ocean  \\\n",
       "61630   URLID_GNPF     1.0    1.0     0.0    0.0    0.0     0.0   1.0    0.0   \n",
       "32747   URLID_IIAA     0.0    0.0     1.0    0.0    0.0     0.0   3.0    0.0   \n",
       "231181  URLID_OOXK     0.0    2.0     6.0    0.0    0.0     0.0   0.0    0.0   \n",
       "152952  URLID_HCWK     0.0    0.0     5.0    2.0    0.0     0.0   0.0    0.0   \n",
       "22218   URLID_RXZL     0.0    0.0     0.0    0.0    1.0     0.0   1.0    0.0   \n",
       "\n",
       "        math  ...  audio  elect  decision  petrol  mouse  danger  heart  soul  \\\n",
       "61630    0.0  ...    0.0    4.0       0.0     0.0    0.0     0.0    0.0   0.0   \n",
       "32747    0.0  ...    0.0    1.0       0.0     0.0    0.0     0.0    0.0   0.0   \n",
       "231181   1.0  ...    0.0    2.0       0.0     1.0    0.0     0.0    0.0   0.0   \n",
       "152952   0.0  ...    0.0    0.0       0.0     0.0    0.0     2.0    0.0   0.0   \n",
       "22218    0.0  ...    0.0    2.0       0.0     0.0    0.0     0.0    0.0   0.0   \n",
       "\n",
       "        grade  elderly  \n",
       "61630     0.0      0.0  \n",
       "32747     1.0      0.0  \n",
       "231181    0.0      0.0  \n",
       "152952    0.0      0.0  \n",
       "22218     0.0      0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = df_test.columns[1:]\n",
    "medians = df_test[selected_columns].median()\n",
    "df_test[selected_columns] = df_test[selected_columns].fillna(medians)\n",
    "filled_nan_counts = df_test.isna().sum()\n",
    "print(filled_nan_counts)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56cfbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, df, th):\n",
    "    probabilities = model.predict_proba(df)[:, 1]\n",
    "    \n",
    "    return (probabilities >= th).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "009617fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLID</th>\n",
       "      <th>length</th>\n",
       "      <th>word_present</th>\n",
       "      <th>edited_2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61630</th>\n",
       "      <td>URLID_GNPF</td>\n",
       "      <td>19961.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32747</th>\n",
       "      <td>URLID_IIAA</td>\n",
       "      <td>33490.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231181</th>\n",
       "      <td>URLID_OOXK</td>\n",
       "      <td>32132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152952</th>\n",
       "      <td>URLID_HCWK</td>\n",
       "      <td>43180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22218</th>\n",
       "      <td>URLID_RXZL</td>\n",
       "      <td>35918.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             URLID   length  word_present  edited_2023\n",
       "61630   URLID_GNPF  19961.0             1            1\n",
       "32747   URLID_IIAA  33490.0             1            0\n",
       "231181  URLID_OOXK  32132.0             1            1\n",
       "152952  URLID_HCWK  43180.0             0            0\n",
       "22218   URLID_RXZL  35918.0             0            1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = 'final_part2.csv'\n",
    "# isolate features\n",
    "features = df_test.drop('URLID', axis=1).values\n",
    "scaler_test = StandardScaler()\n",
    "features = scaler_test.fit_transform(features)\n",
    "\n",
    "# make predictions on test dataset\n",
    "l_pred = model_dtr.predict(features)\n",
    "wp_pred = get_predictions(rf_wp, features, selected_threshold_wp)\n",
    "e2_pred = get_predictions(rf_e2, features, selected_threshold_e2)\n",
    "\n",
    "output_df = df_test[['URLID']].copy()\n",
    "output_df['length'] = l_pred\n",
    "output_df['word_present'] = wp_pred\n",
    "output_df['edited_2023'] = e2_pred\n",
    "\n",
    "output_df.to_csv(output_file, index=False)\n",
    "\n",
    "output_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
